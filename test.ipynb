{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported libraries...\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This notebook is used for testing the network, \n",
    "SINGLE INFERENCE - for testing random google images\n",
    "TESTING IMAGES - running the testing sets through the model\n",
    "            and evaluating the results\n",
    "\n",
    "@Author: Aaron Ward\n",
    "'''\n",
    "import tensorflow as tf\n",
    "import os, os.path\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import skimage\n",
    "from skimage import transform, exposure\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "\n",
    "print('Imported libraries...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAINED_MODEL = os.getcwd() + '/output/'\n",
    "\n",
    "IMAGE_PATH = os.getcwd() + '/test/happy.jpg'\n",
    "# IMAGE_PATH = os.getcwd() + '/test/anger1.jpg'\n",
    "# IMAGE_PATH = os.getcwd() + '/test/surprise.jpg'\n",
    "# IMAGE_PATH = os.getcwd() + '/test/neutral.jpg'\n",
    "# IMAGE_PATH = os.getcwd() + '/test/sad.jpg'\n",
    "# IMAGE_PATH = os.getcwd() + '/test/fear.jpg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./output/trained_model.ckpt\n",
      "Angry - 317\n",
      "Fear - 9\n",
      "Happy - 11\n",
      "Netral - 12\n",
      "Sad - 1\n",
      "Suprise - 0\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session('', tf.Graph())\n",
    "with sess.graph.as_default():\n",
    "    # Read meta graph and checkpoint to restore tf session\n",
    "    saver = tf.train.import_meta_graph(TRAINED_MODEL + \"trained_model.ckpt.meta\")\n",
    "    saver.restore(sess, \"./output/trained_model.ckpt\")\n",
    "\n",
    "######################################### SINGLE INFERENCE ##################################################################\n",
    "    '''\n",
    "        Test single images from google at a time with the model\n",
    "        @NOTE: Will not perform as well because images aren't cropped around the facial area\n",
    "    '''\n",
    "#     #Read a single image from a file.\n",
    "#     print('Original Image')\n",
    "#     img=mpimg.imread(IMAGE_PATH)\n",
    "#     imgplot = plt.imshow(img)\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n",
    "#     img = np.array(img)\n",
    "\n",
    "#     image = Image.open(IMAGE_PATH)\n",
    "#     image = image.convert('L')\n",
    "#     image = image.resize((50, 50), Image.ANTIALIAS)\n",
    "        \n",
    "#     print('Resized and Grayscaled Image')\n",
    "#     imgplot = plt.imshow(image, cmap='gray')\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "#     image = np.expand_dims(np.array(image), axis = 0)\n",
    "                       \n",
    "    # Get pointers to relevant tensors in graph\n",
    "    graph = tf.get_default_graph()\n",
    "    x = graph.get_tensor_by_name(\"X_placeholder:0\") # input\n",
    "    y = graph.get_tensor_by_name(\"Y_placeholder:0\") # label - not using this, unless we want to calculate loss\n",
    "    is_training = graph.get_tensor_by_name( \"is_training:0\" ) \n",
    "    prediction = graph.get_tensor_by_name( \"Prediction:0\" ) # these will be results\n",
    "\n",
    "#     classification = sess.run(prediction, feed_dict = {x: image, is_training : True})   \n",
    "#     classes = np.argmax( classification, axis = 1 ) # add highest probability result to classes\n",
    "\n",
    "#     if   classes[0] == 0:\n",
    "#         print('Predicted: Angry')\n",
    "#     elif classes[0] == 1:\n",
    "#         print('Predicted: Fear')\n",
    "#     elif classes[0] == 2:\n",
    "#         print('Predicted: Happy')\n",
    "#     elif classes[0] == 3:\n",
    "#         print('Predicted: neutral')\n",
    "#     elif classes[0] == 4:\n",
    "#         print('Predicted: sad')\n",
    "#     elif classes[0] == 5:\n",
    "#         print('Predicted: suprised')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  ################################# TESTING IMAGES ##################################################################        \n",
    "    '''\n",
    "     This is for feed the entire testing set for each class into the model to \n",
    "     calculate the misclassifications\n",
    "\n",
    "    '''\n",
    "TESTING_DIR = os.getcwd() + '/data/testing/0/'\n",
    "num_angry = 0\n",
    "num_happy = 0\n",
    "num_fear = 0\n",
    "num_neutral = 0\n",
    "num_sad = 0\n",
    "num_suprise = 0\n",
    "list = os.listdir(TESTING_DIR)\n",
    "for file in list:    \n",
    "    image = Image.open(TESTING_DIR + file)\n",
    "    image = image.convert('L')\n",
    "    image = image.resize((50, 50), Image.ANTIALIAS)\n",
    "    image = np.expand_dims(np.array(image), axis = 0)\n",
    "\n",
    "    classification = sess.run(prediction, feed_dict = {x: image, is_training : True})   \n",
    "    classes = np.argmax( classification, axis = 1 ) # add highest probability result to classes\n",
    "\n",
    "    if   classes[0] == 0:\n",
    "        num_angry += 1\n",
    "    elif classes[0] == 1:\n",
    "        num_fear += 1\n",
    "    elif classes[0] == 2:\n",
    "        num_happy+= 1\n",
    "    elif classes[0] == 3:\n",
    "        num_neutral += 1\n",
    "    elif classes[0] == 4:\n",
    "        num_sad += 1\n",
    "    elif classes[0] == 5:\n",
    "        num_suprise += 1\n",
    "\n",
    "print('Angry -', num_angry)\n",
    "print('Fear -', num_fear)\n",
    "print('Happy -', num_happy)\n",
    "print('Netral -', num_neutral)\n",
    "print('Sad -', num_sad)\n",
    "print('Suprise -', num_suprise)\n",
    "\n",
    "\n",
    "    #  #######################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
